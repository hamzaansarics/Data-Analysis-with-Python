{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How to import pandas and check the version? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How to create a series from a list, numpy array and dict?\n",
    " - Create a pandas series from each of the items below: a list, numpy and a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(len(mylist))\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser1=pd.Series(mylist)\n",
    "ser2=pd.Series(myarr)\n",
    "ser3=pd.Series(mydict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How to convert the index of a series into a column of a dataframe?\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   Convert the series ser into a dataframe with its index as another column on    the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser = pd.Series(mydict)\n",
    "df=pd.DataFrame()\n",
    "pd.concat([df,ser]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. How to combine many series to form a dataframe?\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   Combine ser1 and ser2 to form a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26),name='DD')\n",
    "df=pd.DataFrame()\n",
    "dd=pd.concat([df,ser2])\n",
    "dd[ser2.name]=ser1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. How to assign name to the series’ index?\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   Give a name to the series ser calling it ‘alphabets’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser.name='fdsa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. How to get the items of series A not present in series B?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   From ser1 remove items present in ser2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "for a in ser1:\n",
    "    if a not in list(ser2):\n",
    "        print(a)\n",
    "ser_u = pd.Series(np.union1d(ser1, ser2))  # union\n",
    "ser_i = pd.Series(np.intersect1d(ser1, ser2))  # intersect\n",
    "ser1[~ser1.isin(ser2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  8. How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Get all items of ser1 and ser2 not common to both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.normal(10, 5, 25))\n",
    "np.percentile(ser,[0,25,50,75,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. How to get frequency counts of unique items of a series?\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   Calculte the frequency counts of each unique value ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "    From ser, keep the top 2 most frequent items as it is and replace\n",
    "    everything else as ‘Other’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "ser.loc[(ser.max()!=ser) & ((ser.max()-1)!=ser)]='Other'\n",
    "ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. How to bin a numeric series to 10 groups of equal size?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Bin the series ser into 10 equal deciles and replace the values with the bin\n",
    "   name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.random(20))\n",
    "\n",
    "# Solution\n",
    "# pd.qcut(ser, q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1], labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. How to convert a numpy array to a dataframe of given shape? (L1)\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   Reshape the series ser into a dataframe with 7 rows and 5 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "arr=np.array(ser)\n",
    "arr=arr.reshape(7,5)\n",
    "pd.DataFrame(data=arr)\n",
    "ser.values.reshape(7,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. How to find the positions of numbers that are multiples of 3 from a series?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Find the positions of numbers that are multiples of 3 from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "ser[ser.values==(3*3)].index\n",
    "np.argwhere(ser%3==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. How to extract items at given positions from a series\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   From ser, extract the items at positions in list pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "ser.loc[pos]\n",
    "ser.take(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. How to stack two series vertically and horizontally ?\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   Stack ser1 and ser2 vertically and horizontally (to form a dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "ser1.append(ser2) # Vertically\n",
    "pd.concat([ser1,ser2],axis=1) # Horizentally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. How to get the positions of items of series A in another series B?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Get the positions of items of ser2 in ser1 as a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 0, 8]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "ser1[ser1.isin(ser2)].index\n",
    "# Solution 1\n",
    "[np.where(i == ser1)[0].tolist()[0] for i in ser2]\n",
    "\n",
    "# Solution 2\n",
    "[pd.Index(ser1).get_loc(i) for i in ser2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. How to compute the mean squared error on a truth and predicted series?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Compute the mean squared error of truth and pred series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "np.mean((truth-pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. How to convert the first character of each element in a series to uppercase?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Change the first character of each word to upper case in each word of ser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "ser.str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. How to calculate the number of characters in each word in a series?\n",
    " - Difficulty Level: L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "[len(i) for i in ser]\n",
    "ser.str.len()\n",
    "ser.map(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. How to compute difference of differences between consequtive numbers of a series?\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   Difference of differences between the consequtive numbers of ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "\n",
    "def consq(x):\n",
    "    ser=[]\n",
    "    c=0\n",
    "    for i in x:\n",
    "        c+=1\n",
    "        if c==len(x):\n",
    "            return pd.Series(ser)\n",
    "        else:\n",
    "            ser.append(float(x[c]-i))\n",
    "consq(ser)\n",
    "print(ser.diff().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. How to convert a series of date-strings to a timeseries?\n",
    " - Difficiulty Level: L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "pd.to_datetime(ser)\n",
    "\n",
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "ser.map(lambda x: parse(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. How to get the day of month, week number, day of year and day of week from a series of date strings?\n",
    " - Difficiulty Level: L2\n",
    "\n",
    "   Get the day of month, week number, day of year and day of week from ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "ser=pd.to_datetime(ser)\n",
    "ser.dt.month\n",
    "ser.dt.dayofyear\n",
    "ser.dt.dayofweek\n",
    "ser.dt.week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. How to convert year-month string to dates corresponding to the 4th day of the month?\n",
    " - Difficiulty Level: L2\n",
    "\n",
    "   Change ser to dates that start with 4th of the respective months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "ser=pd.to_datetime(ser)\n",
    "ser.dt.year.astype('str')+'-0'+ser.dt.month.astype('str')+'-'+ser.dt.day.astype('str').replace('1','04')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. How to filter words that contain atleast 2 vowels from a series?\n",
    " - Difficiulty Level: L2\n",
    " \n",
    "   From ser, extract words that contain atleast 2 vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "import re\n",
    "c=0\n",
    "o=0\n",
    "vowel=['a','e','i','o','u']\n",
    "# for i in ser:\n",
    "#     for w in vowel:\n",
    "#         if w in i.lower():\n",
    "#             o+=1\n",
    "#             if o==2:\n",
    "#                 o=0\n",
    "#                 print(i)\n",
    "#     o=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. How to filter valid emails from a series?\n",
    " - Difficiulty Level: L1\n",
    "\n",
    "   Extract the valid emails from the series emails. The regex pattern for valid    emails is provided as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+'\n",
    "import re\n",
    "for s in emails:\n",
    "    print(re.findall(re.compile(r'[\\w\\.]+@[\\w\\.]+'),s))\n",
    "    print(re.findall(re.compile(pattern),s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. How to get the mean of a series grouped by another series?\n",
    " - Difficiulty Level: L2\n",
    "\n",
    "   Compute the mean of weights of each fruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "weights.groupby(fruit).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. How to compute the euclidean distance between two series?\n",
    " - Difficiulty Level: L2\n",
    "\n",
    "   Compute the euclidean distance between series (points) p and q, without \n",
    "   using a packaged formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.16590212458495"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "sum((p - q)**2)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. How to find all the local maxima (or peaks) in a numeric series?\n",
    " - Difficiulty Level: L3\n",
    "\n",
    "   Get the positions of peaks (values surrounded by smaller values on both\n",
    "   sides) in ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "# Solution\n",
    "dd = np.diff(np.sign(np.diff(ser)))\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29. How to replace missing spaces in a string with the least frequent character?\n",
    " - Replace the spaces in my_str with the least frequent character.\n",
    "\n",
    "   Difficiulty Level: L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dbccdebcabedcgade'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str = 'dbc deb abed gade'\n",
    "from collections import Counter\n",
    "for key,val in Counter(my_str).items():\n",
    "    if val==min(Counter(my_str).values()):\n",
    "        aa=my_str.replace(' ',key)\n",
    "        break\n",
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?\n",
    " - Difficiulty Level: L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=pd.Series(['2000/01/01'])\n",
    "start=pd.to_datetime(start)\n",
    "a=1\n",
    "v=1\n",
    "for i in range(1,11):\n",
    "    if i==1:\n",
    "         print(start)\n",
    "    elif a<=28:\n",
    "        a+=7\n",
    "        if a>28:\n",
    "                a=5\n",
    "                v+=1\n",
    "                s=start.dt.year.astype('str')+'-'+str(v)+'-'+str(start.dt.day.astype('int')+a)+str(np.random.randint(0,10,1))[0]  \n",
    "                print(pd.Series(s))\n",
    "        else:\n",
    "                s=start.dt.year.astype('str')+'-'+str(v)+'-'+str(start.dt.day.astype('int')+a)+str(np.random.randint(0,10,1))\n",
    "                print(pd.Series(s))\n",
    "ser = pd.Series(np.random.randint(1,10,10), pd.date_range('2000-01-01', periods=10, freq='W-SAT'))\n",
    "pd.Series(np.random.randint(1,10,10),pd.date_range('2000-01-01',periods=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?\n",
    " - Difficiulty Level: L2\n",
    "\n",
    "   ser has missing dates and values. Make all missing dates appear and fill up    with value from previous date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series([1,10,3, np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "\n",
    "\n",
    "# Solution\n",
    "ser.resample('D').ffill()  # fill with previous value\n",
    "\n",
    "# Alternatives\n",
    "ser.resample('D').bfill()  # fill with next value\n",
    "ser.resample('D').bfill().ffill()  # fill next else prev value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32. How to compute the autocorrelations of a numeric series?\n",
    " - Difficiulty Level: L3\n",
    "\n",
    "   Compute autocorrelations for the first 10 lags of ser. Find out which lag  \n",
    "   has the largest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "# Solution\n",
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "print(autocorrelations[1:])\n",
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33. How to import only every nth row from a csv file to create a dataframe?\n",
    " - Difficiulty Level: L2\n",
    "\n",
    "   Import every 50th row of BostonHousing dataset as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('I:\\Text Datasets\\CSV\\drinks.csv',nrows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34. How to change column values when importing csv to a dataframe?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Import the boston housing dataset, but while importing change the 'medv' \n",
    "   (median house value) column so that values < 25 becomes ‘Low’ and > 25 \n",
    "   becomes ‘High’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: Using converter parameter\n",
    "pd.read_csv('I:\\Text Datasets\\CSV\\drinks.csv', converters={'medv': lambda x: 'High' if float(x) > 25 else 'Low'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35. How to create a dataframe with rows as strides from a given series?\n",
    " - Difficiulty Level: L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L =  pd.Series(range(15))\n",
    "\n",
    "def gen_strides(a, stride_len=5, window_len=5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len=2, window_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 36. How to import only specified columns from a csv file?\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   Import ‘crim’ and ‘medv’ columns of the BostonHousing dataset as a \n",
    "   dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('I:\\Text Datasets\\CSV\\drinks.csv',usecols=[3,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent.\n",
    "- Difficulty Level: L2\n",
    "\n",
    "  Get the number of rows, columns, datatype and summary statistics of each  \n",
    "  column of the Cars93 dataset. Also get the numpy array and list equivalent of \n",
    "  the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=pd.read_csv('I:\\Text Datasets\\CSV\\drinks.csv')\n",
    "pp.head()\n",
    "pp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 38. How to extract the row and column number of a particular cell with given criterion?\n",
    " - Difficulty Level: L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=pd.read_csv('I:\\Text Datasets\\CSV\\drinks.csv')\n",
    "pp.head()\n",
    "pp[pp.spirit_servings.values==pp.spirit_servings.max()].index\n",
    "pp[pp.spirit_servings.values==pp.spirit_servings.max()].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 39. How to rename a specific columns in  dataframe?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Rename the column Type as CarType in df and replace the ‘.’ in column names \n",
    "   with ‘_’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=pd.read_csv('I:\\Text Datasets\\CSV\\drinks.csv')\n",
    "pp.head()\n",
    "pp.columns=pp.columns.str.replace('country','---')\n",
    "pp.rename(columns={'---':'oooooooo'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40. How to check if a dataframe has any missing values?\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   Check if df has any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp=pd.read_csv('I:\\Text Datasets\\CSV\\drinks.csv')\n",
    "pp.isnull().sum()\n",
    "pp.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 41. How to count the number of missing values in each column?\n",
    " - Difficulty Level: L2 \n",
    "   Count the number of missing values in each column of df. Which column has   \n",
    "   the maximum number of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('I:\\\\Text Datasets\\\\CSV\\\\titanic.csv')\n",
    "df.head(2)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42. How to replace missing values of multiple numeric columns with the mean?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Replace missing values in Min.Price and Max.Price columns with their  \n",
    "   respective mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp=pd.read_csv(r'I:\\Text Datasets\\CSV\\titanic.csv')\n",
    "# #Example\n",
    "# pp['Age','Embarked','Cabin'].apply(lambda x:pp.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 43. How to use apply function on existing columns with global variables as additional arguments?\n",
    " - Difficulty Level: L3\n",
    "\n",
    "   In df, use apply method to replace the missing values in Min.Price with the \n",
    "   column’s mean and those in Max.Price with the column’s median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "d = {'Min.Price': np.nanmean, 'Max.Price': np.nanmedian}\n",
    "df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x, d: x.fillna(d[x.name](x)), args=(d, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 44. How to select a specific column from a dataframe as a dataframe instead of a series?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Get the first column (a) in df as a dataframe (rather than as a Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=pd.read_csv(r'I:\\Text Datasets\\CSV\\titanic.csv')\n",
    "pp[['Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 45. How to change the order of columns of a dataframe?\n",
    " - Difficulty Level: L3\n",
    "\n",
    " - Actually 3 questions.\n",
    "\n",
    "    - In df, interchange columns 'a' and 'c'.\n",
    "    - Create a generic function to interchange two columns, without hardcoding       column names.\n",
    "\n",
    "    -  Sort the columns in reverse alphabetical order, that is colume 'e' first \n",
    "       through column 'a' last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=pd.read_csv('I:\\Text Datasets\\CSV\\drinks.csv')\n",
    "pp.head()\n",
    "pp.loc[:,np.random.choice(pp.columns,np.array(list(set(np.random.randint(0,len(pp.columns),1)))))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 46. How to set the number of rows and columns displayed in the output?\n",
    "- Difficulty Level: L2\n",
    "\n",
    "  Change the pamdas display settings on printing the dataframe df it shows a  \n",
    "  maximum of 10 rows and 10 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.config.CallableDynamicDoc at 0x221039d8748>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp=pd.read_csv('I:\\Text Datasets\\CSV\\drinks.csv')\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.reset_option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 47. How to format or suppress scientific notations in a pandas dataframe?\n",
    " -  Difficulty Level: L2\n",
    "\n",
    "    Suppress scientific notations like ‘e-03’ in df and print upto 4 numbers   \n",
    "    after decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n",
    "pd.options.display.float_format = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 48. How to format all the values in a dataframe as percentages?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Format the values in column 'random' of df as percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "pd.DataFrame(pd.Series(round(df.random*100,2),name='random').astype('str')+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 49. How to filter every nth row in a dataframe?\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   From df, filter the 'Manufacturer', 'Model' and 'Type' for every 20th row \n",
    "   starting from 1st (row 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=pd.read_csv('I:\\Text Datasets\\CSV\\drinks.csv')\n",
    "pp.loc[::20,['country','Years']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50. How to create a primary key index by combining relevant columns?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   In df, Replace NaNs with ‘missing’ in columns 'Manufacturer', 'Model' and   \n",
    "   'Type' and create a index as a combination of these three columns and check \n",
    "   if the index is a primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=pd.read_csv('I:\\Text Datasets\\CSV\\drinks.csv')\n",
    "pp=pp.astype(object)\n",
    "pp['index']=pp.loc[:].str.cat(['country','beer_servings','continent'],sep='_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 51. How to get the row number of the nth largest value in a column? \n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Find the row position of the 5th largest value of column 'a' in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))\n",
    "df.sort_values('c',inplace=True)\n",
    "df.c.values[-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 52. How to find the position of the nth largest value greater than a given value? \n",
    " - Difficulty Level: L2\n",
    "\n",
    "   In ser, find the position of the 2nd largest value greater than the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(np.random.randint(1, 100, 15))\n",
    "ser[ser>ser.mean()].sort_values()[2:3].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 53. How to get the last n rows of a dataframe with row sum > 100?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Get the last two rows of df whose row sum is greater than 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n",
    "def sum_last2rows(data):\n",
    "    index=[]\n",
    "    count=0\n",
    "    for ind,row in data.iterrows():\n",
    "        if df.iloc[-ind].sum()>100:\n",
    "            count+=1\n",
    "            index.append(-ind)\n",
    "        if count==3:\n",
    "            break\n",
    "    return df.iloc[index[1:]]\n",
    "sum_last2rows(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 54. How to find and cap outliers from a series or dataframe column?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Replace all values of ser in the lower 5%ile and greater than 95%ile with \n",
    "   respective 5th and 95th %ile value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.logspace(-2, 2, 30))\n",
    "cond=np.percentile(ser,q=[5,95])\n",
    "ser.loc[ser>cond[0]]=cond[1]\n",
    "ser.loc[ser<cond[0]]=cond[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 55. How to reshape a dataframe to the largest possible square after removing the negative values?\n",
    " - Difficulty Level: L3\n",
    "\n",
    "   Reshape df to the largest possible square with negative values removed. Drop \n",
    "   the smallest values if need be. The order of the positive numbers in the \n",
    "   result should remain the same as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can't understand properly to this ?\n",
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))\n",
    "arr = df[df > 0].values.flatten()\n",
    "arr_qualified = arr[~np.isnan(arr)]\n",
    "\n",
    "# Step 2: find side-length of largest possible square\n",
    "n = int(np.floor(arr_qualified.shape[0]**.5))\n",
    "\n",
    "# Step 3: Take top n^2 items without changing positions\n",
    "top_indexes = np.argsort(arr_qualified)[::-1]\n",
    "output = np.take(arr_qualified, sorted(top_indexes[:n**2])).reshape(n, -1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 56. How to swap two rows of a dataframe?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Swap rows 1 and 2 in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "temp=df.loc[0].copy()\n",
    "df.loc[0]=df.loc[1].copy()\n",
    "df.loc[1]=temp.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 57. How to reverse the rows of a dataframe?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Reverse all the rows of dataframe df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "# df.loc[df.index.sort_values(ascending=False)]\n",
    "df.iloc[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 58. How to create one-hot encodings of a categorical variable (dummy variables)? \n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Get one-hot encodings for column 'a' in the dataframe df and append it as      columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n",
    "ndf=pd.get_dummies(df.a)\n",
    "pd.concat([ndf,df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 59. Which column contains the highest number of row-wise maximum values? \n",
    "- Difficulty Level: L2\n",
    "\n",
    "  Obtain the column name with the highest number of row-wise maximum’s in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column with highest row maxes:  1\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1))\n",
    "print('Column with highest row maxes: ', df.apply(np.argmax, axis=1).value_counts().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60. How to create a new column that contains the row number of nearest column by euclidean distance?\n",
    " - Create a new column such that, each row contains the row number of nearest      row-record by euclidean distance.\n",
    "\n",
    "   Difficulty Level: L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "def near_to_ed(data):\n",
    "    ED_VAL=[]\n",
    "    IND_VAL=[]\n",
    "    runs=list('abcdefghij')\n",
    "    for s in range(len(runs)-1):\n",
    "        ED_VAL.append((sum(data.loc[runs[s]]-data.loc[runs[s+1]])**2)**.5)\n",
    "        IND_VAL.append(runs[s])\n",
    "    ED=pd.Series(ED_VAL,name='ED_VALS')\n",
    "    data.reset_index(inplace=True)\n",
    "    dataset=pd.concat([data,ED],axis=1)\n",
    "    dataset.dropna(how='any',inplace=True)\n",
    "    return dataset.sort_values('ED_VALS')\n",
    "dd=near_to_ed(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 61. How to know the maximum possible correlation value of each column against other columns?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Compute maximum possible absolute correlation value of each column against      other columns in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Correlation possible for each column:  [0.65 0.65 0.81 0.62 0.79 0.81 0.63 0.4  0.79 0.74]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))\n",
    "df\n",
    "# Solution\n",
    "abs_corrmat = np.abs(df.corr())\n",
    "max_corr = abs_corrmat.apply(lambda x: sorted(x)[-2])\n",
    "print('Maximum Correlation possible for each column: ', np.round(max_corr.tolist(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 62. How to create a column containing the minimum by maximum of each row?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Compute the minimum-by-maximum for every row of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "#Solution 1\n",
    "df.apply(lambda x:np.min(x)/np.max(x),axis=1)\n",
    "\n",
    "#Solution 2\n",
    "df.loc[:].min(axis=1)/df.loc[:].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 63. How to create a column that contains the penultimate value in each row?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Create a new column 'penultimate' which has the second largest value of each    row of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1),columns=list('abcdefghij'))\n",
    "df['pentilative']=df.apply(lambda x:x.sort_values().unique()[-2],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 64. How to normalize all columns in a dataframe?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   - Normalize all columns of df by subtracting the column mean and divide by  \n",
    "    standard deviation.\n",
    "    \n",
    "   - Range all columns of df such that the minimum value in each column is 0 \n",
    "     and \n",
    "    max is 1.\n",
    " - Don’t use external packages like sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "df=df.apply(lambda x:(x-x.mean())/x.std() ,axis=1)\n",
    "for ind,row in df.iterrows():\n",
    "    df.loc[ind][df.loc[ind]>0]=1\n",
    "    df.loc[ind][df.loc[ind]<0]=0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 65. How to compute the correlation of each row with the suceeding row? \n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Compute the correlation of each row of df with its succeeding row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.27, 0.05, -0.39, 0.42, 0.24, -0.06, 0.55]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "# Solution\n",
    "[df.loc[i].corr(df.loc[i+1]).round(2) for i in range(df.shape[0]-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 66. How to replace both the diagonals of dataframe with 0?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Replace both values in both diagonals of df with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n",
    "\n",
    "#Solution 1\n",
    "def diagnols_zero(dataframe):\n",
    "    sp=dataframe.shape[0]-1\n",
    "    for ind,row in dataframe.iterrows():\n",
    "        dataframe.iloc[ind][ind]=0\n",
    "        dataframe[sp-ind][ind]=0\n",
    "    return dataframe\n",
    "diagnols_zero(df)\n",
    "\n",
    "#Solution 2\n",
    "for i in range(df.shape[0]):\n",
    "    df.iat[i, i] = 0\n",
    "    df.iat[df.shape[0]-i-1, i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 67. How to get the particular group of a groupby dataframe by key?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   This is a question related to understanding of grouped dataframe. From     \n",
    "   df_grouped, get the group belonging to 'apple' as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'col2': np.random.rand(9),\n",
    "                   'col3': np.random.randint(0, 15, 9)})\n",
    "\n",
    "#Solution 1\n",
    "df[df.col1=='apple']\n",
    "\n",
    "#Solution 2\n",
    "grp=df.groupby('col1')\n",
    "grp.get_group('apple')\n",
    "\n",
    "#Solution 3\n",
    "for i,diff in grp:\n",
    "    if i=='apple':\n",
    "        print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 68. How to get the n’th largest value of a column when grouped by another column?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   In df, find the second largest value of 'taste' for 'banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4100978066499881"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "#Solution 1\n",
    "df[df.fruit=='apple'].sort_values('rating').rating.iloc[-2]\n",
    "\n",
    "#Solution 2\n",
    "df.groupby('fruit').get_group('apple').sort_values('rating').rating.iloc[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 69. How to compute grouped mean on pandas dataframe and keep the grouped column as another column (not index)?\n",
    " - Difficulty Level: L1\n",
    "\n",
    "   In df, Compute the mean price of every fruit, while keeping the fruit as  \n",
    "   another column instead of an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fruit\n",
       "apple     3.000000\n",
       "banana    4.666667\n",
       "orange    5.666667\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})\n",
    "df.groupby('fruit').price.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 70. How to join two dataframes by 2 columns so they have only the common rows?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Join dataframes df1 and df2 by ‘fruit-pazham’ and ‘weight-kilo’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 6)})\n",
    "\n",
    "# Solution\n",
    "pd.merge(df1, df2, how='inner', left_on=['fruit', 'weight'], right_on=['pazham', 'kilo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 71. How to remove rows from a dataframe that are present in another dataframe?\n",
    " - Difficulty Level: L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] ,\n",
    "                    'weight': ['high', 'medium', 'low'] ,\n",
    "                    'price': [20,40,50]})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'banana', 'pine'],\n",
    "                    'kilo': ['high', 'low','medium'],\n",
    "                    'price': [20,60,40]})\n",
    "print(df1[~df1.isin(df2).all(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 72. How to get the positions where values of two columns match?\n",
    " - Difficulty Level: L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6], dtype=int64),)"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n",
    "                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})\n",
    "\n",
    "#Solution 1\n",
    "df[df.fruit1==df.fruit2].index\n",
    "\n",
    "#Solution 2\n",
    "np.where(df.fruit1==df.fruit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 73. How to create lags and leads of a column in a dataframe?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Create two new columns in df, one of which is a lag1 (shift column a down by \n",
    "   1 row) of column ‘a’ and the other is a lead1 (shift column b up by 1 row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "\n",
    "#Solution 1\n",
    "df['lag_a']=df['a'][1:]\n",
    "df['lead_a']=df['a'][:df.shape[0]-1]\n",
    "\n",
    "#Solution 2\n",
    "df['ss']=df['a'].shift(1)\n",
    "df['ss1']=df['a'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 74. How to get the frequency of unique values in the entire dataframe?\n",
    " - Difficulty Level: L2\n",
    " \n",
    "   Get the frequency of unique values in the entire dataframe df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "pd.value_counts(df.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75. How to split a text column into two separate columns?\n",
    " - Difficulty Level: L2\n",
    "\n",
    "   Split the string column in df to form a dataframe with 3 columns as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\"STD, City    State\",\n",
    "\"33, Kolkata    West Bengal\",\n",
    "\"44, Chennai    Tamil Nadu\",\n",
    "\"40, Hyderabad    Telengana\",\n",
    "\"80, Bangalore    Karnataka\"], columns=['row'])\n",
    "df\n",
    "\n",
    "#Solution 1\n",
    "def spliter(dataframe):\n",
    "    STD=[dataframe.row.str.split(',')[i][0] for i in range(df.shape[0])]\n",
    "    CITY=[dataframe.row.str.split(',')[i][1].split('   ')[0] for i in range(df.shape[0])]\n",
    "    STATE=[dataframe.row.str.split(',')[i][1].split('   ')[1] for i in range(df.shape[0])]\n",
    "    dataframe['STD']=pd.Series(STD)\n",
    "    dataframe['CITY']=pd.Series(CITY)\n",
    "    dataframe['STATE']=pd.Series(STATE)\n",
    "    return dataframe\n",
    "spliter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
